{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LiQxt2Q0h0eR"
   },
   "source": [
    "# **Computational Physics Project**\n",
    "\n",
    "### Numerical Integration of Quantum Probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k6J9TaBYh0eU"
   },
   "source": [
    "#### **Preamble**\n",
    "First, we import the necessary modules for the project and define any constants we expect to use (such as machine epsilon)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-JrX4nzQh0eW"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import interpolate\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Define machine epsilon for default floats\n",
    "eps = np.finfo(float).eps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F0MJl7krh0ea"
   },
   "source": [
    "#### **Newton-Cotes Integration**\n",
    "We will use object-oriented programming for this project. Let us define a generic integration class which we will use for argument validation. This will be a parent class for the `TrapeziumRule` and `SimpsonsRule` classes which will inherit its properties. We define the required attributes for the Newton-Cotes methods in this class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DgoRpaoWh0eb"
   },
   "outputs": [],
   "source": [
    "class NC_Integration(object):\n",
    "    \"\"\"Generic class to hold attributes for Newton-Cotes integration methods.\n",
    "    \n",
    "    This class does not contain any processing methods of its own. It is used\n",
    "    to hold all of the variables required to perform a Newton-Cotes\n",
    "    integration. The class will provide argument validation and processing.\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    fn : function\n",
    "        The integrand.\n",
    "\n",
    "    a : scalar\n",
    "        The lower limit of the integral.\n",
    "\n",
    "    b : scalar\n",
    "        The upper limit of the integral.\n",
    "\n",
    "    max_error : scalar\n",
    "        The accuracy goal for the integration.\n",
    "\n",
    "    max_steps : scalar\n",
    "        The maximum number of steps to perform the integral.\n",
    "    \n",
    "    plot : boolean\n",
    "        A boolean to indicate if plot should be output.\n",
    "\n",
    "    integral : scalar\n",
    "        The value of the integral.\n",
    "\n",
    "    error : scalar\n",
    "        An estimate for the error on the integral.\n",
    "\n",
    "    iterations : integer\n",
    "        The number of function evaluations required.\n",
    "    \n",
    "    steps : integer\n",
    "        The number of recursions until desired accuracy achieved.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, fn, a, b, max_error, max_steps, plot):\n",
    "        \"\"\"Initialises NC_Integration class.\n",
    "        \n",
    "        Declares the required attributes and performs necessary argument\n",
    "        validation for Newton-Cotes integration methods.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        fn : function\n",
    "            The integrand.\n",
    "        \n",
    "        a : scalar\n",
    "            The lower limit of the integral.\n",
    "        \n",
    "        b : scalar\n",
    "            The upper limit of the integral.\n",
    "        \n",
    "        max_error : scalar\n",
    "            The accuracy goal for the integration.\n",
    "        \n",
    "        max_steps : integer\n",
    "            The maximum number of steps allowed to achieve accuracy goal.\n",
    "        \n",
    "        plot : boolean\n",
    "            A boolean to indicate if plot should be output.\n",
    "        \n",
    "        Raises\n",
    "        ------\n",
    "        ValueError\n",
    "            If `fn` is not a callable function.\n",
    "            If `a`, `b` are not scalars or `a` is not less than `b`.\n",
    "            If `max_error` is not a scalar or `max_error` is too small.\n",
    "            If `max_steps` is not an integer or is too small.\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        if callable(fn) == False:\n",
    "            raise ValueError(\"The integrand `fn` must be a callable function.\")\n",
    "        \n",
    "        if np.isfinite(a) == False or np.isfinite(b) == False:\n",
    "            raise ValueError(\"Integral limits `a` and `b` must be finite \" +\n",
    "                             \"numbers.\")\n",
    "        \n",
    "        if b < a:\n",
    "            raise ValueError(\"The upper limit `b` must be larger than the \" +\n",
    "                             \"lower limit `a`.\")\n",
    "        \n",
    "        if max_error < 1.0e3 * eps:\n",
    "            raise ValueError(\"The specified accuracy `max_error` is too small.\")\n",
    "        \n",
    "        if max_steps < 2:\n",
    "            raise ValueError(\"Argument `max_steps` must be an integer \" +\n",
    "                             \"greater than 2.\")\n",
    "        \n",
    "        # Validation successful, initiate class variables\n",
    "        self.fn = fn\n",
    "        self.a = a\n",
    "        self.b = b\n",
    "        self.max_error = max_error\n",
    "        self.max_steps = int(max_steps)\n",
    "        self.plot = plot\n",
    "        \n",
    "        self.integral = 0.0\n",
    "        self.error = 1.0e30\n",
    "        self.iterations = 0\n",
    "        self.steps = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Csenwz9qh0ee"
   },
   "source": [
    "#### **Trapezium Rule**\n",
    "Let us define a trapezium integration class which can be created with a function and some integration region. The class will contain information about the integral, including the integral value, the error in the value and the number of iterations executed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rEl3NGYlh0ef"
   },
   "outputs": [],
   "source": [
    "class TrapeziumRule(NC_Integration):\n",
    "    \"\"\"Class to perform integration using the trapezium rule.\n",
    "    \n",
    "    This class uses an iterative approach to estimate an integral using the\n",
    "    trapezium rule. We iteratively increase the number of function evaluations\n",
    "    until the desired accuracy is achieved. The class inherits from the generic\n",
    "    NC_Integration class and inherits all of its attributes.\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    fn : function\n",
    "        The integrand.\n",
    "\n",
    "    a : scalar\n",
    "        The lower limit of the integral.\n",
    "\n",
    "    b : scalar\n",
    "        The upper limit of the integral.\n",
    "\n",
    "    max_error : scalar, optional, default = 1.0e-3\n",
    "        The accuracy goal for the integration.\n",
    "\n",
    "    max_steps : scalar, optional, default = 25\n",
    "        The maximum number of steps to perform the integral.\n",
    "    \n",
    "    plot : boolean\n",
    "            A boolean to indicate if plot should be output.\n",
    "\n",
    "    integral : scalar\n",
    "        The value of the integral.\n",
    "\n",
    "    error : scalar\n",
    "        An estimate for the error on the integral.\n",
    "\n",
    "    iterations : integer\n",
    "        The number of function evaluations required.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, fn, a, b, max_error=1.0e-3, max_steps=25, plot=True):\n",
    "        \"\"\"Initialises TrapeziumRule class.\n",
    "        \n",
    "        This class performs trapezium rule integration iteratively until the\n",
    "        desired accuracy is achieved. The class inherits its attributes from the\n",
    "        NC_Integration parent class, which performs all of the necessary\n",
    "        argument validation.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        fn : function\n",
    "            The integrand.\n",
    "        \n",
    "        a : scalar\n",
    "            The lower limit of the integral.\n",
    "        \n",
    "        b : scalar\n",
    "            The upper limit of the integral.\n",
    "        \n",
    "        max_error : scalar, optional, default = 1.0e-3\n",
    "            The accuracy goal for the integration.\n",
    "        \n",
    "        max_steps : integer, optional, default = 25\n",
    "            The maximum number of steps to perform the integral.\n",
    "        \n",
    "        plot : boolean, optional, default = True\n",
    "            A boolean to indicate if plot should be output.\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        # Inherit from NC_Integration class\n",
    "        super().__init__(fn, a, b, max_error=max_error, max_steps=max_steps, plot=plot)\n",
    "        \n",
    "        # Compute the integral\n",
    "        self.integrate()\n",
    "    \n",
    "    def integrate(self):\n",
    "        \"\"\"Performs the integration using the trapezium rule.\n",
    "        \n",
    "        This method makes calls to the trapezium step method to iteratively\n",
    "        update the estimate of the integral. The function does not return any\n",
    "        value - it updates the class attributes when the integration is\n",
    "        complete.\n",
    "        \n",
    "        Raises\n",
    "        ------\n",
    "        ValueError\n",
    "            If the integral did not converge to the desired accuracy in the\n",
    "                given number of steps.\n",
    "        \n",
    "        See Also\n",
    "        --------\n",
    "        SimpsonsRule.integrate : performs the integral using Simpson's Rule.\n",
    "        MC_Integration.integrate : perfomrs integral using Monte Carlo methods.\n",
    "\n",
    "        Notes\n",
    "        -----\n",
    "        This function uses an iterative approach to repeatedly apply the\n",
    "        trapezium rule with a reduced step size until the desired accuracy is\n",
    "        achieved. The additional function evaluations required for each\n",
    "        iterative step are performed in the static method `trapezium_step`.\n",
    "\n",
    "        References\n",
    "        ----------\n",
    "        Numerical Recipes in C, Integration of Functions, Elementary Algorithms\n",
    "        W. H. Press, Cambridge University Press\n",
    "\n",
    "        Examples\n",
    "        --------\n",
    "        Integrate a function f on an interval x = 0.0 to x = 1.5708\n",
    "\n",
    "        >>> def f(x): return np.cos(x)\n",
    "        >>> t = TrapeziumRule(f, 0.0, 1.5708)\n",
    "        >>> t.integral\n",
    "        0.9997991933740931\n",
    "\n",
    "        Specify an accuracy goal of 1.0e-6 for the integral\n",
    "\n",
    "        >>> t = TrapeziumRule(f, 0.0, 1.5708, max_error=1.0e-6)\n",
    "        >>> t.integral\n",
    "        0.9999998039009074\n",
    "\n",
    "        Get error estimate and number of function evaluations\n",
    "\n",
    "        >>> t = TrapeziumRule(f, 0.0, 1.5708)\n",
    "        >>> (t.integral, t.error, t.iterations)\n",
    "        (0.9997991933740931, 0.0006025166533906168, 33)\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        # Initialise variable to hold integral value\n",
    "        t0 = -1.0e30\n",
    "        iters = 1\n",
    "        \n",
    "        # Repeat for max_steps iterations\n",
    "        for j in range(1, self.max_steps):\n",
    "            \n",
    "            # Update integral estimate from previous iteration t0\n",
    "            t1 = TrapeziumRule.trapezium_step(self.fn, self.a, self.b, j, t0)\n",
    "            \n",
    "            # At each step, we perform 2 ** (j-2) function calls, ceil ensures\n",
    "            # that we have two total iterations for j = 1\n",
    "            iters += np.ceil(2 ** (j - 2))\n",
    "            \n",
    "            # Prevent erroneous early convergence\n",
    "            if j >= 2:\n",
    "                \n",
    "                # Exit if error restriction satisfied\n",
    "                if (abs(t1 - t0) < self.max_error * abs(t1) or\n",
    "                    (abs(t0) < eps and abs(t1) < eps)):\n",
    "                    \n",
    "                    # Update class attribute values\n",
    "                    self.integral = t1\n",
    "                    self.error = abs(t1 - t0) * abs(t1)\n",
    "                    self.iterations = int(iters)\n",
    "                    \n",
    "                    if self.plot == True:\n",
    "                        self.make_plot()\n",
    "                    \n",
    "                    # No further iterations required, return from function\n",
    "                    return\n",
    "            \n",
    "            # Update integral estimate\n",
    "            t0 = t1\n",
    "        \n",
    "        # Integral did not converge in max_steps, raise error\n",
    "        raise ValueError(\"The integral did not converge in the maximum number \" +\n",
    "                         \"of steps.\")\n",
    "    \n",
    "    def make_plot(self):\n",
    "        # Internal function for graph plotting\n",
    "\n",
    "        # Plot the integrand\n",
    "        X1 = np.linspace(self.a, self.b, 500)\n",
    "        Y1 = [self.fn(x1) for x1 in X1]\n",
    "        \n",
    "        # Plot the abscissas\n",
    "        X2 = np.linspace(self.a, self.b, self.iterations)\n",
    "        Y2 = [self.fn(x2) for x2 in X2]\n",
    "        \n",
    "        plt.plot(X1, Y1, label=\"f\", color=\"black\")\n",
    "        plt.plot(X2, Y2, \"-x\", ls=\"dashed\", label=\"Trapezium Rule\", color=\"red\")\n",
    "        plt.fill_between(X2, Y2, color=\"#eeeeee\")\n",
    "        plt.legend()\n",
    "        plt.xlabel(\"$x$\")\n",
    "        plt.ylabel(\"$y$\")\n",
    "        plt.grid()\n",
    "        plt.show()\n",
    "    \n",
    "    @staticmethod\n",
    "    def trapezium_step(fn, a, b, n, s=0.0):\n",
    "        \"\"\"Computes the n-th step of the trapzeium rule integration.\n",
    "        \n",
    "        This function performs the n-th step of the trapezium rule using the\n",
    "        value `s`, which is the integral estimate from the previous step. This\n",
    "        is a static method to be re-used in the `SimpsonsRule` class.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        fn : function\n",
    "            The integrand.\n",
    "        \n",
    "        a : scalar\n",
    "            The lower limit of the integral.\n",
    "        \n",
    "        b : scalar\n",
    "            The upper limit of the integral.\n",
    "        \n",
    "        n : integer\n",
    "            The step (iteration) of the integral.\n",
    "        \n",
    "        s : scalar, optional, default = 0.0\n",
    "            Estimate of the integral from the previous iteration.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        s1 : scalar\n",
    "            Estimate of the integral from this iteration.\n",
    "        \n",
    "        See Also\n",
    "        --------\n",
    "        TrapeziumRule.integrate : performs integral using the trapezium rule.\n",
    "\n",
    "        Notes\n",
    "        -----\n",
    "        The integral is performed using a iterative approach to the trapezium\n",
    "        rule where each iterative step only evaluates the function at the new\n",
    "        interval spacing without repeating evaluations. The result of the new\n",
    "        evaluations is added to the integral from the previous iterative step,\n",
    "        which is passed as an argument.\n",
    "\n",
    "        References\n",
    "        ----------\n",
    "        Numerical Recipes in C, Integration of Functions, Elementary Algorithms\n",
    "        W. H. Press, Cambridge University Press\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        # Error validation occurs in parent class, proceed with integration\n",
    "        if n == 1:\n",
    "            # First iterative step requires evaluation at endpoints\n",
    "            return 0.5 * (b - a) * (fn(a) + fn(b))\n",
    "        else:\n",
    "            # Declare variable to hold sum of new evaluations\n",
    "            sum_yn = 0.0\n",
    "            \n",
    "            # Declare interval increment for this iteration\n",
    "            inc = (b - a) / (2 ** (n - 2))\n",
    "            \n",
    "            # Declare first new abscissa to evaluate\n",
    "            xn = a + 0.5 * inc\n",
    "            \n",
    "            # Sample to upper abscissa limit, account for machine accuracy\n",
    "            while xn < b - eps:\n",
    "                sum_yn += fn(xn)\n",
    "                xn += inc\n",
    "            \n",
    "            # Return the new integral estimate\n",
    "            return 0.5 * (s + inc * sum_yn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Trapezium Rule - Validation**\n",
    "We will perform some known integrals to verify that the trapezium rule routine is integrating correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return x ** 2\n",
    "\n",
    "t = TrapeziumRule(f, -1.0, 1.0, max_error=1.0e-4, plot=False)\n",
    "print(\"Integral: \", t.integral)\n",
    "print(\"Absolute Error: \", t.error)\n",
    "print(\"Function Evaluations: \", t.iterations)\n",
    "print(\"\\n\")\n",
    "# Answer = 2 / 3\n",
    "\n",
    "def f(x):\n",
    "    return 1 - 2 * x ** 2\n",
    "\n",
    "t = TrapeziumRule(f, 0.0, 1.0, max_error=1.0e-5, plot=False)\n",
    "print(\"Integral: \", t.integral)\n",
    "print(\"Absolute Error: \", t.error)\n",
    "print(\"Function Evaluations: \", t.iterations)\n",
    "print(\"\\n\")\n",
    "# Answer = 1 / 3\n",
    "\n",
    "def f(x):\n",
    "    return np.cos(x)\n",
    "\n",
    "t = TrapeziumRule(f, 0.0, np.pi, max_error=1.0e-3, plot=False)\n",
    "print(\"Integral: \", t.integral)\n",
    "print(\"Absolute Error: \", t.error)\n",
    "print(\"Function Evaluations: \", t.iterations)\n",
    "print(\"\\n\")\n",
    "# Answer = 0\n",
    "\n",
    "def f(x):\n",
    "    return -np.exp(-(x - 0.5) ** 2)\n",
    "\n",
    "t = TrapeziumRule(f, 0.0, 1.0, max_error=1.0e-6, plot=False)\n",
    "print(\"Integral: \", t.integral)\n",
    "print(\"Absolute Error: \", t.error)\n",
    "print(\"Function Evaluations: \", t.iterations)\n",
    "# Answer = -0.922562012826"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 330
    },
    "colab_type": "code",
    "id": "1RpyjK7Ph0ei",
    "outputId": "1c9423bf-b1e7-4121-c3a4-cf0ea513b725"
   },
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return np.exp(-x ** 2) / np.sqrt(np.pi)\n",
    "\n",
    "t = TrapeziumRule(f, 0.0, 2.0, max_error=1.0e-6, plot=True)\n",
    "print(\"Integral: \", t.integral)\n",
    "print(\"Absolute Error: \", t.error)\n",
    "print(\"Function Evaluations: \", t.iterations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g6Y7pfYvh0em"
   },
   "source": [
    "#### **Simpson's Rule**\n",
    "Let us define a Simpson's integration class which can be created with a function and some integration region. The class will contain information about the integral, including the integral value, the error in the value and the number of iterations executed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YVRTx40nh0en"
   },
   "outputs": [],
   "source": [
    "class SimpsonsRule(NC_Integration):\n",
    "    \"\"\"Class to perform integration using the Simpson's rule.\n",
    "    \n",
    "    This class uses an iterative approach to estimate an integral using the\n",
    "    Simpson's rule. We iteratively increase the number of function evaluations\n",
    "    until the desired accuracy is achieved. The class inherits its attributes\n",
    "    from the generic NC_Integration class. This class uses the static\n",
    "    `trapezium_step` method from the `TrapeziumRule` class to calculate an\n",
    "    estimate for the Simpson's rule.\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    fn : function\n",
    "        The integrand.\n",
    "\n",
    "    a : scalar\n",
    "        The lower limit of the integral.\n",
    "\n",
    "    b : scalar\n",
    "        The upper limit of the integral.\n",
    "\n",
    "    max_error : scalar, optional, default = 1.0e-3\n",
    "        The accuracy goal for the integration.\n",
    "\n",
    "    max_steps : scalar, optional, default = 25\n",
    "        The maximum number of steps to perform the integral.\n",
    "    \n",
    "    plot : boolean\n",
    "            A boolean to indicate if plot should be output.\n",
    "\n",
    "    integral : scalar\n",
    "        The value of the integral.\n",
    "\n",
    "    error : scalar\n",
    "        An estimate for the error on the integral.\n",
    "\n",
    "    iterations : integer\n",
    "        The number of function evaluations required.\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, fn, a, b, max_error=1.0e-3, max_steps=25, plot=True):\n",
    "        \"\"\"Initialises SimpsonsRule class.\n",
    "        \n",
    "        This class performs numerical integration using the Simpson's rule. The\n",
    "        class relies on the static trapezium_step function and the relationship\n",
    "        between two consecutive iterative steps of the trapezium rule and the\n",
    "        Simpson's rule to iteratively update the integral value until the\n",
    "        desired accuracy is achieved. The class inherits its attributes from the\n",
    "        NC_Integration parent class, which performs all of the necessary\n",
    "        argument validation.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        fn : function\n",
    "            The integrand.\n",
    "        \n",
    "        a : scalar\n",
    "            The lower limit of the integral.\n",
    "        \n",
    "        b : scalar\n",
    "            The upper limit of the integral.\n",
    "        \n",
    "        max_error : scalar, optional, default = 1.0e-3\n",
    "            The accuracy goal for the integration.\n",
    "        \n",
    "        max_steps : integer, optional, default = 25\n",
    "            The maximum number of steps to perform the integral.\n",
    "        \n",
    "        plot : boolean, optional, default = True\n",
    "            A boolean to indicate if plot should be output.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Inherit from NC_Integration class\n",
    "        super().__init__(fn, a, b, max_error=max_error, max_steps=max_steps, plot=plot)\n",
    "        \n",
    "        # Compute the integral\n",
    "        self.integrate()\n",
    "    \n",
    "    def integrate(self):\n",
    "        \"\"\"Performs the integration using the Simpson's rule.\n",
    "        \n",
    "        This method makes calls to the trapezium step method to iteratively\n",
    "        update the estimate of the integral. The Simpson's rule estimate is\n",
    "        calculated using the relationship with the trapezium rule. The function\n",
    "        does not return any value - it updates the class attributes when the\n",
    "        integration is complete.\n",
    "        \n",
    "        Raises\n",
    "        ------\n",
    "        ValueError\n",
    "            If the integral did not converge to the desired accuracy in the\n",
    "                given number of steps.\n",
    "        \n",
    "        See Also\n",
    "        --------\n",
    "        TrapeziumRule.integrate : performs integral using the trapezium rule.\n",
    "        TrapeziumRule.trapezium_step : performs one iteration of trapezium rule.\n",
    "        MC_Integration.integrate : performs integral using Monte Carlo methods.\n",
    "\n",
    "        Notes\n",
    "        -----\n",
    "        This function uses an iterative approach to repeatedly apply the\n",
    "        trapezium rule with a reduced step size until the desired accuracy is\n",
    "        achieved. The additional function evaluations required for each\n",
    "        iterative step are performed in the static method `trapezium_step`. The\n",
    "        function exploits the relationship between two iterative steps of the\n",
    "        trapezium rule to estimate the integral using the Simpson's rule.\n",
    "\n",
    "        References\n",
    "        ----------\n",
    "        Numerical Recipes in C, Integration of Functions, Elementary Algorithms\n",
    "        W. H. Press, Cambridge University Press\n",
    "\n",
    "        Examples\n",
    "        --------\n",
    "        Integrate a function f on an interval x = 0.0 to x = 1.5708\n",
    "\n",
    "        >>> def f(x): return np.cos(x)\n",
    "        >>> s = SimpsonRule(f, 0.0, 1.5708)\n",
    "        >>> s.integral\n",
    "        1.0000082955949947\n",
    "\n",
    "        Specify an accuracy goal of 1.0e-6 for the integral\n",
    "\n",
    "        >>> s = TrapeziumRule(f, 0.0, 1.5708, max_error=1.0e-6)\n",
    "        >>> s.integral\n",
    "        1.0000000322585565\n",
    "\n",
    "        Get error estimate and number of function evaluations\n",
    "\n",
    "        >>> s = TrapeziumRule(f, 0.0, 1.5708)\n",
    "        >>> (s.integral, s.error, s.iterations)\n",
    "        (1.0000082955949947, 0.00012629064304969795, 9)\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        # Declare variables for trapezium rule, Simpson's rule estimates\n",
    "        t0 = -1.0e30\n",
    "        s0 = -1.0e30\n",
    "        iters = 1\n",
    "        \n",
    "        # Repeat for max_steps iterations\n",
    "        for j in range(1, self.max_steps):\n",
    "            \n",
    "            # Update integral estimate from previous iteration t0\n",
    "            t1 = TrapeziumRule.trapezium_step(self.fn, self.a, self.b, j, t0)\n",
    "            \n",
    "            # Calculate Simpson's rule estimate, S_i = (4T_(i+1) - T_i) / 3\n",
    "            s1 = (4.0 * t1 - t0) / 3.0\n",
    "            \n",
    "            # At each step, we perform 2 ** (j-2) function calls, ceil ensures\n",
    "            # that we have two total iterations for j = 1\n",
    "            iters += np.ceil(2 ** (j - 2))\n",
    "            \n",
    "            # Prevent erroneous early convergence to solution\n",
    "            if j >= 2:\n",
    "                \n",
    "                # Exit if error restriction satisfied\n",
    "                if (abs(s1 - s0) < self.max_error * abs(s1) or\n",
    "                    (abs(s0) < eps and abs(s1) < eps)):\n",
    "                    \n",
    "                    # Update class attributes\n",
    "                    self.integral = s1\n",
    "                    self.error = abs(s1 - s0) * abs(s1)\n",
    "                    self.iterations = int(iters)\n",
    "                    \n",
    "                    if self.plot == True:\n",
    "                        self.make_plot()\n",
    "                    \n",
    "                    # No further iterations required, return from function\n",
    "                    return\n",
    "            \n",
    "            # Update trapezium rule and Simpson's rule estimates\n",
    "            t0 = t1\n",
    "            s0 = s1\n",
    "        \n",
    "        # Integral did not converge in max_steps, raise error\n",
    "        raise ValueError(\"The integral did not converge in the maximum number\" +\n",
    "                         \"of steps.\")\n",
    "    \n",
    "    def make_plot(self):\n",
    "        # Internal function for graph plotting\n",
    "\n",
    "        # Plot the integrand\n",
    "        X1 = np.linspace(self.a, self.b, 500)\n",
    "        Y1 = [self.fn(x1) for x1 in X1]\n",
    "        plt.plot(X1, Y1, label=\"f\", color=\"black\")\n",
    "        \n",
    "        # Plot the absciccas\n",
    "        X2 = np.linspace(self.a, self.b, self.iterations)\n",
    "        Y2 = [self.fn(x2) for x2 in X2]\n",
    "        plt.plot(X2, Y2, \"x\", color=\"red\")\n",
    "\n",
    "        # Plot the Lagrange interpolation between each set of three points\n",
    "        for i in range(1, len(X2) - 1, 2):\n",
    "\n",
    "            # Extract three relevant abscissas\n",
    "            X3 = X2[i - 1:i + 2]\n",
    "            Y3 = Y2[i - 1:i + 2]\n",
    "\n",
    "            # Apply second order Lagrange polynomial between three abscissas\n",
    "            lp = interpolate.lagrange(X3, Y3)\n",
    "            \n",
    "            # Plot the interpolated polynomial over the three abscissas\n",
    "            X4 = np.linspace(X2[i - 1], X2[i + 1], 5)\n",
    "            Y4 = [lp(x) for x in X4]\n",
    "            plt.plot(X4, Y4, ls=\"dashed\", color=\"red\")\n",
    "            plt.fill_between(X4, Y4, color=\"#eeeeee\")\n",
    "\n",
    "        # Include interpolated Lagrange polynomial in the legend\n",
    "        plt.plot(0, 0, ls=\"dashed\", label=\"Simpson's Rule\", color=\"red\")\n",
    "        \n",
    "        plt.legend()\n",
    "        plt.xlabel(\"$x$\")\n",
    "        plt.ylabel(\"$y$\")\n",
    "        plt.grid()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Simpson's Rule - Validation**\n",
    "We will perform some known integrals to verify that Simpson's rule routine is integrating correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return x ** 2\n",
    "\n",
    "s = SimpsonsRule(f, -1.0, 1.0, max_error=1.0e-4, plot=False)\n",
    "print(\"Integral: \", s.integral)\n",
    "print(\"Absolute Error: \", s.error)\n",
    "print(\"Function Evaluations: \", s.iterations)\n",
    "print(\"\\n\")\n",
    "# Answer = 2 / 3\n",
    "\n",
    "def f(x):\n",
    "    return 1 - 2 * x ** 2\n",
    "\n",
    "s = SimpsonsRule(f, 0.0, 1.0, max_error=1.0e-5, plot=False)\n",
    "print(\"Integral: \", s.integral)\n",
    "print(\"Absolute Error: \", s.error)\n",
    "print(\"Function Evaluations: \", s.iterations)\n",
    "print(\"\\n\")\n",
    "# Answer = 1 / 3\n",
    "\n",
    "def f(x):\n",
    "    return np.cos(x)\n",
    "\n",
    "s = SimpsonsRule(f, 0.0, np.pi, max_error=1.0e-3, plot=False)\n",
    "print(\"Integral: \", s.integral)\n",
    "print(\"Absolute Error: \", s.error)\n",
    "print(\"Function Evaluations: \", s.iterations)\n",
    "print(\"\\n\")\n",
    "# Answer = 0\n",
    "\n",
    "def f(x):\n",
    "    return -np.exp(-(x - 0.5) ** 2)\n",
    "\n",
    "s = SimpsonsRule(f, 0.0, 1.0, max_error=1.0e-6, plot=False)\n",
    "print(\"Integral: \", s.integral)\n",
    "print(\"Absolute Error: \", s.error)\n",
    "print(\"Function Evaluations: \", s.iterations)\n",
    "# Answer = -0.922562012826"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 330
    },
    "colab_type": "code",
    "id": "zY8zJYwEh0ep",
    "outputId": "a5aacba2-b08c-486f-d5ba-f59ba3314790"
   },
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return np.exp(-x ** 2) / np.sqrt(np.pi)\n",
    "\n",
    "s = SimpsonsRule(f, 0.0, 2.0, max_error=1.0e-6, plot=True)\n",
    "print(\"Integral: \", s.integral)\n",
    "print(\"Error: \", s.error)\n",
    "print(\"Function Evaluations: \", s.iterations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TzwbXBsfh0et"
   },
   "source": [
    "#### **Monte Carlo Integration**\n",
    "We wish to use Monte Carlo methods to calculate the required integral. We will later extend the Monte Carlo class to use importance sampling with a given probability distribution function. First, we will declare a random sampling class which will take a probability distribution function and an inverse cumulative distribution function as arguments. The sampling class will use the transformation method to map values from a uniformly distributed region $[0, 1)$ to the required region over which the PDF is defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ulxj4GjTh0eu"
   },
   "outputs": [],
   "source": [
    "# Define a fixed seed\n",
    "np.random.seed(22092009)\n",
    "\n",
    "class Sample():\n",
    "    \"\"\"Generates random variates given a PDF and corresponding inverse CDF.\n",
    "    \n",
    "    This class uses the transformation method to generate random deviates from a\n",
    "    probability distribution given the corresponding inverse cumulative\n",
    "    distribution function.\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    pdf : function\n",
    "        The sampling probability distribution function.\n",
    "\n",
    "    inverse_cdf : function\n",
    "        The inverse cumulative distribution function of `pdf`.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, pdf, inverse_cdf):\n",
    "        \"\"\"Initialises Sample class.\n",
    "        \n",
    "        The class exposes a sample method to generate random deviates according\n",
    "        to a probability distribution function.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        pdf : function\n",
    "            The normalised sampling probability distribution function.\n",
    "        \n",
    "        inverse_cdf : function\n",
    "            The inverse cumulative distribution function of `pdf`.\n",
    "        \n",
    "        Raises\n",
    "        ------\n",
    "        ValueError\n",
    "            If `pdf` or `inverse_cdf` is not a callable function.\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        if callable(pdf) == False or callable(inverse_cdf) == False:\n",
    "            raise ValueError(\"Arguments `pdf` and `inverse_cdf` must be \" +\n",
    "                             \"callable functions.\")\n",
    "        \n",
    "        self.pdf = pdf\n",
    "        self.inverse_cdf = inverse_cdf\n",
    "    \n",
    "    def sample(self):\n",
    "        \"\"\"Generates a random deviate from `pdf`.\n",
    "        \n",
    "        This method generates a random deviate using the transformation method.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        rv : scalar\n",
    "            A random variate drawn from `pdf`.\n",
    "        \n",
    "        Notes\n",
    "        -----\n",
    "        This function generates a sample from the `pdf` distribution using its\n",
    "        corresponding `inverse_cdf` function as according to the transformation\n",
    "        method. The inverse CDF function must return a numeric value for all\n",
    "        values in the interval [0, 1).\n",
    "\n",
    "        References\n",
    "        ----------\n",
    "        Numerical Recipes in C, Random Numbers, Transformation Method\n",
    "        W. H. Press, Cambridge University Press\n",
    "\n",
    "        Examples\n",
    "        --------\n",
    "        Sample a function from a uniform distribution on the interval [0, 2]\n",
    "\n",
    "        >>> def pdf(x): return 1.0 / (2.0 - 0.0)\n",
    "        >>> def inv_cdf(x): return x * 2\n",
    "        >>> s = Sample(pdf, inv_cdf)\n",
    "        >>> s.sample()\n",
    "        1.7534370293465757\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        return self.inverse_cdf(np.random.rand())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2irv888Gh0ez"
   },
   "source": [
    "We now define a generic Monte Carlo integration class. This will act as the parent class for the Monte Carlo integration method with importance sampling and adaptive recursion. We will use this class to hold information about the properties of the required integral as well as storing the results of the integration later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ff6EMz5Ah0e0"
   },
   "outputs": [],
   "source": [
    "class MC_Integration():\n",
    "    \"\"\"Parent class to hold attributes for Monte Carlo integration methods.\n",
    "    \n",
    "    This class is used to hold all of the variables required to perform a Monte\n",
    "    Carlo integration simulation. The class will provide argument validation and\n",
    "    processing. The class exposes a method for simple Monte Carlo integration.\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    fn : function\n",
    "        The integrand.\n",
    "\n",
    "    a : scalar\n",
    "        The lower limit of the integral.\n",
    "\n",
    "    b : scalar\n",
    "        The upper limit of the integral.\n",
    "\n",
    "    max_error : scalar\n",
    "        The accuracy goal for the integration.\n",
    "    \n",
    "    max_samples : integer\n",
    "        The maximum number of samples to perform the integral.\n",
    "    \n",
    "    plot : boolean\n",
    "        A boolean to indicate if plot should be output.\n",
    "    \n",
    "    sample : Sample, optional, default = None\n",
    "        The Sample instance used to generate random deviates. Defaults to a\n",
    "        uniform distribution over the integration region.\n",
    "\n",
    "    integral : scalar\n",
    "        The value of the integral.\n",
    "\n",
    "    error : scalar\n",
    "        An estimate for the error on the integral.\n",
    "\n",
    "    iterations : integer\n",
    "        The number of function evaluations required.\n",
    "        \n",
    "    x_samples : list\n",
    "        A list to hold the x samples which can be plotted later.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, fn, a, b, max_error, max_samples, plot, sample=None):\n",
    "        \"\"\"Initialises MC_Integration class.\n",
    "        \n",
    "        The class exposes an integration method which performs simple Monte\n",
    "        Carlo until either the desired accuracy is achieved or the number of\n",
    "        evaluations exceeds `max_samples`.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        fn : function\n",
    "            The integrand.\n",
    "\n",
    "        a : scalar\n",
    "            The lower limit of the integral.\n",
    "\n",
    "        b : scalar\n",
    "            The upper limit of the integral.\n",
    "\n",
    "        max_error : scalar\n",
    "            The accuracy goal for the integration.\n",
    "\n",
    "        max_samples : integer\n",
    "            The maximum number of samples to perform the integral.\n",
    "        \n",
    "        plot : boolean\n",
    "            A boolean to indicate if plot should be output.\n",
    "        \n",
    "        sample : Sample, optional, default = None\n",
    "            The Sample instance used to generate random deviates. Defaults to a\n",
    "            uniform distribution over the integration region.\n",
    "        \n",
    "        Raises\n",
    "        ------\n",
    "        ValueError\n",
    "            If `fn` is not a callable function.\n",
    "            If `a`, `b` are not scalars or `a` is not less than `b`.\n",
    "            If `max_error` is not a scalar.\n",
    "            If `max_samples` is too small.\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        if callable(fn) == False:\n",
    "            raise ValueError(\"The integrand `fn` must be a callable function.\")\n",
    "        \n",
    "        if np.isfinite(a) == False or np.isfinite(b) == False:\n",
    "            raise ValueError(\"Integral limits `a` and `b` must be finite \" +\n",
    "                             \"numbers.\")\n",
    "        \n",
    "        if b < a:\n",
    "            raise ValueError(\"The upper limit `b` must be larger than the \" +\n",
    "                             \"lower limit `a`.\")\n",
    "        \n",
    "        if np.isfinite(max_error) == False:\n",
    "            raise ValueError(\"Argument `max_error` must be a numeric input.\")\n",
    "        \n",
    "        if max_samples < 5:\n",
    "            raise ValueError(\"Argument `max_samples` must be an integer \" +\n",
    "                             \"greater than 5.\")\n",
    "        \n",
    "        self.fn = fn\n",
    "        self.a = a\n",
    "        self.b = b\n",
    "        self.max_error = max_error\n",
    "        self.max_samples = max_samples\n",
    "        self.sample = sample\n",
    "        self.plot = plot\n",
    "        \n",
    "        # If no sampling distribution provided\n",
    "        if self.sample == None:\n",
    "            \n",
    "            # Define a uniform distribution on [a, b) using anyonymous functions\n",
    "            pdf = lambda x : 1 / (b - a)\n",
    "            inverse_cdf = lambda x : a + (b - a) * x\n",
    "            \n",
    "            # Create a sample instance for a uniform distribution\n",
    "            self.sample = Sample(pdf, inverse_cdf)\n",
    "        \n",
    "        # Initiate variables\n",
    "        self.integral = 0.0\n",
    "        self.error = 1.0e30\n",
    "        self.iterations = 0\n",
    "        self.x_samples = []\n",
    "    \n",
    "    def integrate(self):\n",
    "        \"\"\"Performs the integration using a Monte Carlo simulation.\n",
    "        \n",
    "        This method performs a Monte Carlo simulation to integrate the function\n",
    "        `fn` on [a, b). The attributes of the class are attributed to store the\n",
    "        integral results and no value is returned.\n",
    "        \n",
    "        Raises\n",
    "        ------\n",
    "        ValueError\n",
    "            If the integral did not converge to the desired accuracy in the\n",
    "                given number of steps.\n",
    "        \n",
    "        See Also\n",
    "        --------\n",
    "        TrapeziumRule.integrate : performs integral using the trapezium rule.\n",
    "        SimpsonsRule.integrate : performs integral using Simpsons rule.\n",
    "\n",
    "        Notes\n",
    "        -----\n",
    "        Monte Carlo methods using random number sampling and the law of averages\n",
    "        to approximate integrals. In lower dimensions, Newton-Cotes integrals\n",
    "        are more efficient but Monte Carlo methods scale better with number of\n",
    "        dimensions.\n",
    "\n",
    "        References\n",
    "        ----------\n",
    "        Numerical Recipes in C, Random Numbers, Monte Carlo Integration\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        # Error validation performed on initiation, proceed to integral\n",
    "        n = 0.0\n",
    "        n_var = 0.0\n",
    "        err = 1.0e30\n",
    "        tot = 0\n",
    "        mean_n = 1.0\n",
    "        \n",
    "        # Iterate until desired accuracy is achieved\n",
    "        while (tot < 2500 or err > self.max_error * abs(mean_n)) and tot < self.max_samples:\n",
    "            \n",
    "            # Sample from distribution using Sample instance\n",
    "            xn = self.sample.sample()\n",
    "            self.x_samples.append(xn)\n",
    "            \n",
    "            # Compute the value of the integral based on xn\n",
    "            yn = self.fn(xn) / self.sample.pdf(xn)\n",
    "            n += yn\n",
    "            n_var += yn ** 2\n",
    "            tot += 1\n",
    "            \n",
    "            # Calculate the mean value of the integral based on samples\n",
    "            mean_n = n / tot\n",
    "            var = (n_var / tot - mean_n ** 2) / tot\n",
    "            err = np.sqrt(var)\n",
    "            \n",
    "            # Print progress of integration\n",
    "            if (tot % 250000 == 0):\n",
    "                out = (\"Steps: {:8d}, Integral: {:8.6f}, \" +\n",
    "                       \"Error: {:8.3e}\").format(tot, mean_n, err)\n",
    "                print(out)\n",
    "        \n",
    "        # Update class attributes\n",
    "        self.integral = mean_n\n",
    "        self.error = err\n",
    "        self.iterations = tot\n",
    "        \n",
    "        if self.plot:\n",
    "            self.make_plot()\n",
    "    \n",
    "    def make_plot(self):\n",
    "        # Internal function for graph plotting\n",
    "        \n",
    "        # Plot the abscissas\n",
    "        plt.hist(self.x_samples, bins=24, edgecolor=\"black\", color=\"#cccccc\", density=True)\n",
    "\n",
    "        # Plot sampling PDF\n",
    "        X = np.linspace(self.a, self.b, 500)\n",
    "        Y1 = [self.sample.pdf(x) for x in X]\n",
    "        \n",
    "        plt.plot(X, Y1, label=\"PDF\", c=\"red\")\n",
    "\n",
    "        plt.xlabel(\"$x$\")\n",
    "        plt.ylabel(\"Proportion\")\n",
    "        plt.grid()\n",
    "        plt.legend(loc=3)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PqmjWUdAh0e3"
   },
   "outputs": [],
   "source": [
    "class MonteCarlo_IS(MC_Integration):\n",
    "    \"\"\"Class to perform Monte Carlo integration with importance sampling.\n",
    "    \n",
    "    This class uses an iterative approach to estimate an integral using Monte\n",
    "    Carlo sampling. We sample iteratively from a given probability distribution\n",
    "    and compute the mean value of the integral. If no sampling distribution is\n",
    "    provided, the method defaults to using a uniform PDF (i.e. not importance\n",
    "    sampling).\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    fn : function\n",
    "        The integrand.\n",
    "\n",
    "    a : scalar\n",
    "        The lower limit of the integral.\n",
    "\n",
    "    b : scalar\n",
    "        The upper limit of the integral.\n",
    "\n",
    "    max_error : scalar, optional, default = 1.0e-3\n",
    "        The accuracy goal for the integration.\n",
    "    \n",
    "    plot : boolean, optional, default = True\n",
    "        A boolean to indicate if plot should be output.\n",
    "    \n",
    "    sample : Sample instance, optional, default = None\n",
    "            The Sample instance used to generate random deviates. Defaults to a\n",
    "            uniform distribution over the integration region.\n",
    "\n",
    "    integral : scalar\n",
    "        The value of the integral.\n",
    "\n",
    "    error : scalar\n",
    "        An estimate for the error on the integral.\n",
    "\n",
    "    iterations : integer\n",
    "        The number of function evaluations required.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, fn, a, b, max_error=1.0e-3, plot=True, sample=None):\n",
    "        \"\"\"Initialises MonteCarlo_IS class.\n",
    "        \n",
    "        This class uses an iterative approach to estimate an integral using\n",
    "        Monte Carlo sampling. We sample iteratively from a given probability\n",
    "        distribution and compute the mean value of the integral. If no sampling\n",
    "        distribution is provided, the method defaults to using a uniform PDF\n",
    "        (i.e. not importance sampling).\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        fn : function\n",
    "            The integrand.\n",
    "\n",
    "        a : scalar\n",
    "            The lower limit of the integral.\n",
    "\n",
    "        b : scalar\n",
    "            The upper limit of the integral.\n",
    "\n",
    "        max_error : scalar, optional, default = 1.0e-3\n",
    "            The accuracy goal for the integration.\n",
    "        \n",
    "        plot : boolean, optional, default = True\n",
    "\n",
    "        sample : Sample instance, optional, default = None\n",
    "                The Sample instance used to generate random deviates. Defaults\n",
    "                to a uniform distribution over the integration region.\n",
    "        \n",
    "        See Also\n",
    "        --------\n",
    "        TrapeziumRule.integrate : performs integral using the trapezium rule.\n",
    "        SimpsonsRule.integrate : performs integral using Simpsons rule.\n",
    "\n",
    "        Notes\n",
    "        -----\n",
    "        Monte Carlo methods using random number sampling and the law of averages\n",
    "        to approximate integrals. In lower dimensions, Newton-Cotes integrals\n",
    "        are more efficient but Monte Carlo methods scale better with number of\n",
    "        dimensions.\n",
    "\n",
    "        References\n",
    "        ----------\n",
    "        Numerical Recipes in C, Random Numbers, Monte Carlo Integration\n",
    "\n",
    "        Examples\n",
    "        --------\n",
    "        Integrate a function f on an interval x = 0.0 to x = 1.5708 with a\n",
    "        uniform distribution\n",
    "\n",
    "        >>> def f(x): return np.cos(x)\n",
    "        >>> mc = MonteCarlo_IS(f, 0.0, 1.5708)\n",
    "        >>> mc.integral\n",
    "        0.9997844790190592\n",
    "\n",
    "        Specify an accuracy goal of 1.0e-2 for the integral\n",
    "\n",
    "        >>> mc = MonteCarlo_IS(f, 0.0, 1.5708, max_error=1.0e-2)\n",
    "        >>> mc.integral\n",
    "        1.0169522708504097\n",
    "\n",
    "        Get error estimate and number of function evaluations\n",
    "\n",
    "        >>> mc = MonteCarlo_IS(f, 0.0, 1.5708)\n",
    "        >>> (mc.integral, mc.error, mc.iterations)\n",
    "        (0.999297642053521, 0.0009999996266966391, 233824)\n",
    "\n",
    "        Perform the integral using a linear distribution y = Ax + B\n",
    "        >>> def pdf(x):\n",
    "        >>>   A = -8 / np.pi ** 2\n",
    "        >>>   B = 4 / np.pi\n",
    "        >>>   return A * x + B\n",
    "        >>> def inv_cdf(x):\n",
    "        >>>   A = -8 / np.pi ** 2\n",
    "        >>>   B = 4 / np.pi\n",
    "        >>>   return -B / A - np.sqrt((B / A) ** 2 + 2 * x / A)\n",
    "        >>> s = Sample(pdf, inv_cdf)\n",
    "        >>> mc = MonteCarlo_IS(f, 0.0, 1.5708, sample=s)\n",
    "        >>> (mc.integral, mc.error, mc.iterations)\n",
    "        (1.0002155853673849, 0.000999994355192016, 16784)\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        # Inherit from MC_Integration class\n",
    "        super().__init__(fn, a, b, max_error=max_error, max_samples=int(1.0e30),\n",
    "                         sample=sample, plot=plot)\n",
    "        \n",
    "        # Compute the integral\n",
    "        self.integrate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2TYbWSObh0e5"
   },
   "source": [
    "#### **Simple Monte Carlo**\n",
    "To integrate the quantum probability using a uniform distribution (i.e. not importance sampling), we do not pass any `Sample` obect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 332
    },
    "colab_type": "code",
    "id": "4B-gzdsLh0e8",
    "outputId": "912d0e2d-2bc1-431b-e41c-226fdd28be2d",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Perform the integral using a flat distribution\n",
    "\n",
    "def f(x):\n",
    "    return np.exp(-x ** 2) / np.sqrt(np.pi)\n",
    "    \n",
    "mc = MonteCarlo_IS(f, 0.0, 2.0, max_error=1.0e-3, plot=True)\n",
    "print(\"Integral: \", mc.integral)\n",
    "print(\"Error: \", mc.error)\n",
    "print(\"Function Evaluations: \", mc.iterations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sPl-dbBbh0fH"
   },
   "source": [
    "#### **Monte Carlo with Importance Sampling**\n",
    "To use the Monte Carlo integration technique with importance sampling, we must provide a normalised PDF and the corresponding inverse CDF function. These two functions are provided to the `Sample` class as arguments and the resulting `Sample` instance is passed through the `sample` argument. In this example, we use the PDF suggested in the project guidelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 332
    },
    "colab_type": "code",
    "id": "R3N37Ui0h0fH",
    "outputId": "a975d70a-304d-4223-e0dd-78dcf1739acc",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Importance sampling, PDF and inverse CDF depend on the integration range\n",
    "a = 0.0\n",
    "b = 2.0\n",
    "\n",
    "def pdf(x):\n",
    "    global a, b\n",
    "    if x < a or x > b:\n",
    "        return 0\n",
    "    else:\n",
    "        # Define A and B, PDF normalised irrespective of integration range\n",
    "        A = -0.48 / ((b - a) * (-0.24 * (b + a) + 0.98))\n",
    "        B = 0.98 / ((b - a) * (-0.24 * (b + a) + 0.98))\n",
    "        return A * x + B\n",
    "\n",
    "def inverse_cdf(x):\n",
    "    global a, b\n",
    "    A = -0.48 / ((b - a) * (-0.24 * (b + a) + 0.98))\n",
    "    B = 0.98 / ((b - a) * (-0.24 * (b + a) + 0.98))\n",
    "    return -B / A - np.sqrt((B / A) ** 2 + (2 * (a * B + x) / A) + a ** 2)\n",
    "\n",
    "def f(x):\n",
    "    return np.exp(-x ** 2) / np.sqrt(np.pi)\n",
    "\n",
    "s = Sample(pdf, inverse_cdf)\n",
    "mc = MonteCarlo_IS(f, a, b, max_error=1.0e-3, sample=s, plot=True)\n",
    "print(\"Integral: \", mc.integral)\n",
    "print(\"Error: \", mc.error)\n",
    "print(\"Function Evaluations: \", mc.iterations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HueJHE_ah0fL"
   },
   "source": [
    "#### **Adaptive Monte Carlo**\n",
    "We will define an adaptive Monte Carlo integration technique in which we use a recursive stratification scheme to split the integration region into smaller subregions based on their variance. The subregion with the largest variance is recursively bisected into smaller regions to reduce the total variance. Once the region has been appropriately stratified, each subregion undergoes simple Monte Carlo integration with a linear PDF. The final result is computed by taking an average over each of the subregions weighted by the width of each subregion, which will have a smaller variance than the variance of the single region scheme. To achieve a given accuracy, the same integral is repeated over the subregions multiple times until the variance of the means is less than the required value.\n",
    "\n",
    "To implement this recursive stratification scheme, we will need to define a `Subregion` class which contains all the information necessary to perform simple Monte Carlo integration on itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9W7HQRquh0fL"
   },
   "outputs": [],
   "source": [
    "class Subregion(MC_Integration):\n",
    "    \"\"\"Class to perform Monte Carlo integration on a subregion.\n",
    "    \n",
    "    This class allows each subregion instance to hold all of the necessary\n",
    "    information as attributes to perform simple Monte Carlo integration on\n",
    "    itself.\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    fn : function\n",
    "        The integrand.\n",
    "\n",
    "    a : scalar\n",
    "        The lower limit of the subregion.\n",
    "\n",
    "    b : scalar\n",
    "        The upper limit of the subregion.\n",
    "    \n",
    "    sample : Sample instance\n",
    "            The Sample instance used to generate random deviates for importance\n",
    "            sampling.\n",
    "    \n",
    "    use_IS : boolean\n",
    "            Boolean to indicate if importance sampling should be used on the\n",
    "            subregion. If True, the class applies the given PDF\n",
    "            (y = -0.48x + 0.98), appropriately normalised, to each subregion.\n",
    "\n",
    "    max_samples : integer, optional, default = int(1.0e30)\n",
    "            The maximum number of steps to perform the integral.\n",
    "\n",
    "    integral : scalar\n",
    "        The value of the integral in the subregion.\n",
    "\n",
    "    error : scalar\n",
    "        An estimate for the error on the integral.\n",
    "\n",
    "    iterations : integer\n",
    "        The number of function evaluations required.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, fn, a, b, use_IS, max_samples=100):\n",
    "        \"\"\"Initialises Subregion class.\n",
    "        \n",
    "        This class allows each subregion instance to hold all of the necessary\n",
    "        information as attributes to perform simple Monte Carlo integration on\n",
    "        itself.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        fn : function\n",
    "            The integrand.\n",
    "        \n",
    "        a : scalar\n",
    "            The lower limit of the subregion.\n",
    "        \n",
    "        b : scalar\n",
    "            The upper limit of the subregion.\n",
    "        \n",
    "        use_IS : boolean\n",
    "            Boolean to indicate if importance sampling should be used on the\n",
    "            subregion.\n",
    "        \n",
    "        max_samples : integer, optional, default = 100\n",
    "            The maximum number of steps to perform the integral.\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        self.use_IS = use_IS\n",
    "        \n",
    "        # We sample to max_samples, set max_error = 1.0e-30\n",
    "        max_error = 1.0e-30\n",
    "        \n",
    "        if use_IS == True:\n",
    "            # Define A and B, PDF normalised irrespective of integration range\n",
    "            # A = -0.48 / ((b - a) * (-0.24 * (b + a) + 0.98))\n",
    "            # B = 0.98 / ((b - a) * (-0.24 * (b + a) + 0.98))\n",
    "\n",
    "            # Define adapted PDF over subregion\n",
    "            Ap = (fn(b) - fn(a)) / (b - a)\n",
    "            k_num = -2.0 * (fn(a) - fn(b))\n",
    "            k_den = (fn(a) + fn(b)) * Ap * (b - a) ** 2\n",
    "            k = k_num / k_den\n",
    "            A = k * Ap\n",
    "            B = 1 / (b - a) - 0.5 * k * Ap * (a + b)\n",
    "\n",
    "\n",
    "            # Define normalised PDF and inverse CDF for subregion\n",
    "            def pdf(x):\n",
    "                if x < a or x > b:\n",
    "                    return 0\n",
    "                else:\n",
    "                    return A * x + B\n",
    "\n",
    "            def inverse_cdf(x):\n",
    "                return -B / A + np.sign(A) * np.sqrt((B / A) ** 2 + (2 * (a * B + x) / A) + a ** 2)\n",
    "            \n",
    "            sample = Sample(pdf, inverse_cdf)\n",
    "        else:\n",
    "            sample = None\n",
    "\n",
    "        # Inherit from MC_Integrate class\n",
    "        super().__init__(fn, a, b, max_error=max_error, sample=sample,\n",
    "                         max_samples=max_samples, plot=False)\n",
    "        \n",
    "        # Compute the integral on the subregion\n",
    "        self.integrate()\n",
    "    \n",
    "    def bisect(self):\n",
    "        \"\"\"Bisects a subregion.\n",
    "        \n",
    "        This method bisects a subregion into two equal-width subregions.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        subregions : list\n",
    "            Contains two Subregion instances for the bisected subregion.\n",
    "        \n",
    "        Examples\n",
    "        --------\n",
    "        Define a subregion on an interval and bisect the subregion\n",
    "        \n",
    "        >>> s = Subregion(fn, 0.0, 1.5708)\n",
    "        >>> srs = s.bisect()\n",
    "        >>> (srs[0].a, srs[0].b, srs[1].a, srs[1].b)\n",
    "        (0.0, 0.7854, 0.7854, 1.5708)\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        midpoint = self.midpoint()\n",
    "        return [\n",
    "            Subregion(self.fn, self.a, midpoint, use_IS=self.use_IS),\n",
    "            Subregion(self.fn, midpoint, self.b, use_IS=self.use_IS)\n",
    "        ]\n",
    "    \n",
    "    def width(self):\n",
    "        # Return width of subregion\n",
    "        return self.b - self.a\n",
    "    \n",
    "    def midpoint(self):\n",
    "        # Return midpoint of subregion\n",
    "        return self.a + 0.5 * (self.b - self.a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hJF-j54Rh0fO"
   },
   "outputs": [],
   "source": [
    "class MonteCarlo_AS(MC_Integration):\n",
    "    \"\"\"Class to perform Monte Carlo integration using adaptive sampling.\n",
    "    \n",
    "    This class performs a Monte Carlo integration using recursive stratified\n",
    "    sampling (MISER algorithm) as an adaptive scheme. The region with the\n",
    "    largest variance is recursively bisected until the total error is within the\n",
    "    tolerance.\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    fn : function\n",
    "        The integrand.\n",
    "\n",
    "    a : scalar\n",
    "        The lower limit of the subregion.\n",
    "\n",
    "    b : scalar\n",
    "        The upper limit of the subregion.\n",
    "        \n",
    "    sample : Sample instance, optional, default = None\n",
    "            The Sample instance used to generate random deviates. Defaults to a\n",
    "            uniform distribution over the integration region.\n",
    "\n",
    "    max_error : scalar, optional, default = 1.0e-3\n",
    "            The accuracy goal for the integration.\n",
    "    \n",
    "    use_IS : boolean, optional, default = False\n",
    "            Boolean to indicate if importance sampling should be used on the\n",
    "            subregion. If True, the class applies the given PDF\n",
    "            (y = -0.48x + 0.98), appropriately normalised, to each subregion.\n",
    "\n",
    "    integral : scalar\n",
    "        The value of the integral in the subregion.\n",
    "\n",
    "    error : scalar\n",
    "        An estimate for the error on the integral.\n",
    "\n",
    "    iterations : integer\n",
    "        The number of function evaluations required.\n",
    "    \n",
    "    subregions : list\n",
    "        A list holding the subregions of the integral\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, fn, a, b, max_error=1.0e-3, use_IS=False, plot=False):\n",
    "        \"\"\"Initialises MonteCarlo_AS class.\n",
    "        \n",
    "        This class performs a Monte Carlo integration using recursive stratified\n",
    "        sampling (1D MISER algorithm) as an adaptive scheme. The region with the\n",
    "        largest variance is recursively bisected until the total error is within\n",
    "        the tolerance or the number of subregions exceeds maximum subregions\n",
    "        limit.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        fn : function\n",
    "            The integrand.\n",
    "\n",
    "        a : scalar\n",
    "            The lower limit of the integral.\n",
    "\n",
    "        b : scalar\n",
    "            The upper limit of the integral.\n",
    "\n",
    "        max_error : scalar, optional, default = 1.0e-3\n",
    "            The accuracy goal for the integration.\n",
    "\n",
    "        use_IS : boolean, optional, default = False\n",
    "            Boolean to indicate if importance sampling should be used on the\n",
    "            subregion. If True, the class applies the given PDF\n",
    "            (y = -0.48x + 0.98), appropriately normalised, to each subregion.\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        # Inherit from MC_Integration class\n",
    "        max_samples = int(1.0e30)\n",
    "        self.use_IS = use_IS\n",
    "        super().__init__(fn, a, b, max_error=max_error, plot=plot,\n",
    "                         max_samples=max_samples)\n",
    "        \n",
    "        # Compute the integral\n",
    "        self.integrate()\n",
    "    \n",
    "    def integrate(self):\n",
    "        \"\"\"Performs the integration using adaptive Monte Carlo.\n",
    "        \n",
    "        This method performs a Monte Carlo simulation to integrate the function\n",
    "        `fn` over the region `a` to `b`.\n",
    "        \n",
    "        See Also\n",
    "        --------\n",
    "        TrapeziumRule.integrate : performs integral using the trapezium rule.\n",
    "        SimpsonsRule.integrate : performs integral using Simpsons rule.\n",
    "        MC_Integration.integrate : performs integral using Monte Carlo methods.\n",
    "\n",
    "        Notes\n",
    "        -----\n",
    "        Monte Carlo methods using random number sampling and the law of averages\n",
    "        to approximate integrals. In the adaptive sampling 1D MISER scheme, the\n",
    "        integration subregion with the largest is bisected recursively at each\n",
    "        step and the combined variance is less than the variance of the initial\n",
    "        subregion.\n",
    "\n",
    "        References\n",
    "        ----------\n",
    "        Numerical Recipes in C, Random Numbers, Adaptive Monte Carlo Integration\n",
    "\n",
    "        Examples\n",
    "        --------\n",
    "        Integrate a function f on [0.0, 1.5708) using MISER with flat PDF\n",
    "\n",
    "        >>> def f(x): return np.cos(x)\n",
    "        >>> mc = MonteCarlo_AS(f, 0.0, 1.5708)\n",
    "        >>> mc.integral\n",
    "        1.0006260528995337\n",
    "\n",
    "        Specify an accuracy goal of 1.0e-5 for the integral\n",
    "\n",
    "        >>> mc = MonteCarlo_AS(f, 0.0, 1.5708, max_error=1.0e-5)\n",
    "        >>> mc.integral\n",
    "        0.9999878990120468\n",
    "\n",
    "        Get information about the integral\n",
    "\n",
    "        >>> mc = MonteCarlo_AS(f, 0.0, 1.5708)\n",
    "        >>> (mc.integral, mc.error, mc.iterations, mc.srs)\n",
    "        (1.0011003084835095, 0.0009787300215640482, 2400, 13)\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        # Declare the initial bisected region\n",
    "        max_subregions = 2000\n",
    "        max_samples = 5\n",
    "        mid = self.a + 0.5 * (self.b - self.a)\n",
    "        self.subregions = [\n",
    "            Subregion(self.fn, self.a, mid, use_IS = self.use_IS, max_samples=max_samples),\n",
    "            Subregion(self.fn, mid, self.b, use_IS=self.use_IS, max_samples=max_samples)\n",
    "        ]\n",
    "        \n",
    "        # Declare variables for total error and total integral\n",
    "        grand_error = 1.0e30\n",
    "        grand_integral = 1.0\n",
    "        \n",
    "        # Creating the initial subregions requires 2 * max_samples iterations \n",
    "        iters = 2 * max_samples\n",
    "        \n",
    "        while grand_error > self.max_error * np.abs(grand_integral) and len(self.subregions) < max_subregions:\n",
    "            # Find subregion with highest variance (i.e. error)\n",
    "            j = 0\n",
    "            for i in range(len(self.subregions)):\n",
    "                if self.subregions[i].error > self.subregions[j].error:\n",
    "                    j = i\n",
    "\n",
    "            # Bisect subregion with largest error\n",
    "            bisected_regions = self.subregions[j].bisect()\n",
    "            \n",
    "            # Replace current subregion, append the other subregion\n",
    "            self.subregions[j] = bisected_regions[0]\n",
    "            self.subregions.append(bisected_regions[1])\n",
    "            \n",
    "            # Bisection of subregion requires 2 * max_samples iterations\n",
    "            iters += 2 * max_samples\n",
    "            \n",
    "            # Compute new value for total integral and error\n",
    "            grand_error = np.sqrt(sum([region.error ** 2 for region in self.subregions]))\n",
    "            grand_integral = sum([region.integral for region in self.subregions])\n",
    "        \n",
    "        # Either integral converged or maximum subregion limit exceeded\n",
    "        self.integral = grand_integral\n",
    "        self.error = grand_error\n",
    "        self.iterations = iters\n",
    "        self.srs = len(self.subregions)\n",
    "\n",
    "        if self.plot == True:\n",
    "            self.make_plot()\n",
    "    \n",
    "    def make_plot(self):\n",
    "        # Internal function for graph plotting\n",
    "\n",
    "        # Get midpoints and widths of subregions\n",
    "        X = np.array([[reg.midpoint(), reg.width()] for reg in self.subregions])\n",
    "        \n",
    "        # Plot histogram of subregion widths\n",
    "        plt.hist(X[:, 1], edgecolor=\"black\")\n",
    "        plt.xlabel(\"Subregion Width\")\n",
    "        plt.ylabel(\"Population\")\n",
    "        plt.grid()\n",
    "        plt.show()\n",
    "        \n",
    "        # Plot midpoints and widths\n",
    "        plt.plot(X[:, 0], X[:, 1], \"x\", color=\"black\")\n",
    "        plt.xlabel(\"$x$\")\n",
    "        plt.ylabel(\"Subregion Width\")\n",
    "        plt.grid()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 615
    },
    "colab_type": "code",
    "id": "f_jLGxoMh0fT",
    "outputId": "8730f794-0e66-4a54-d85a-8f2df68b4b9b"
   },
   "outputs": [],
   "source": [
    "# Without importance sampling\n",
    "\n",
    "def f(x):\n",
    "    return np.exp(-x ** 2) / np.sqrt(np.pi)\n",
    "\n",
    "mc = MonteCarlo_AS(f, 0.0, 2.0, max_error=1.0e-3, use_IS=False, plot=True)\n",
    "print(\"Integral: \", mc.integral)\n",
    "print(\"Error: \", mc.error)\n",
    "print(\"Function Evaluations: \", mc.iterations)\n",
    "print(\"Subregions: \", mc.srs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 633
    },
    "colab_type": "code",
    "id": "BOmuPyIDh0fW",
    "outputId": "b14b6106-3d5f-4f8d-a503-54f8b0699ce4"
   },
   "outputs": [],
   "source": [
    "# With importance sampling\n",
    "\n",
    "def f(x):\n",
    "    return np.exp(-x ** 2) / np.sqrt(np.pi)\n",
    "\n",
    "mc = MonteCarlo_AS(f, 0.0, 2.0, max_error=1.0e-3, use_IS=True, plot=True)\n",
    "print(\"Integral: \", mc.integral)\n",
    "print(\"Error: \", mc.error)\n",
    "print(\"Function Evaluations: \", mc.iterations)\n",
    "print(\"Subregions: \", mc.srs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Miscellaneous Plots**\n",
    "The values for these plots were acquired by manually updating the integration parameters and running several trials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = [3, 4, 5, 6, 7, 8, 9]\n",
    "y1 = [17, 33, 129, 513, 1025, 4097, 16385]  # Trapezium Rule\n",
    "y2 = [9, 17, 33, 65, 65, 129, 257]  # Simpson's Rule\n",
    "\n",
    "plt.semilogy(x1, y1, marker=\"x\", label=\"Trapezium Rule\", c=\"black\")\n",
    "plt.semilogy(x1, y2, marker=\"x\", label=\"Simpson's Rule\", c=\"red\")\n",
    "plt.xlabel(\"Accuracy, $-\\log_{10}(\\epsilon)$\")\n",
    "plt.ylabel(\"Evaluations, $K$\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = [1, 2, 3, 4]\n",
    "y1 = [78, 6091, 610119, 61075761]  # Uniform Distribution\n",
    "y2 = [5, 726, 73031, 7341744]  # Linear Distribution\n",
    "\n",
    "x2 = [4, 5, 6, 7, 8]\n",
    "y3 = [61075761, 5.4e9, 5.0e11, 4.7e13, 4.3e15]  # Uniform distribution\n",
    "y4 = [7341744, 8.9e8, 1.0e11, 1.1e13, 1.3e15]  # Linear distribution\n",
    "\n",
    "plt.semilogy(x1, y1, marker=\"x\", label=\"Uniform Distribution\", c=\"black\")\n",
    "plt.semilogy(x1, y2, marker=\"x\", label=\"Linear Distribution\", c=\"red\")\n",
    "plt.semilogy(x2, y3, marker=\"x\", c=\"black\", ls=\"dashed\")\n",
    "plt.semilogy(x2, y4, marker=\"x\", c=\"red\", ls=\"dashed\")\n",
    "plt.xlabel(\"Accuracy, $-\\log_{10}(\\epsilon)$\")\n",
    "plt.ylabel(\"Evaluations, $K$\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xis = [1, 2, 3, 4]\n",
    "yis1 = [78, 6091, 610119, 61075761]\n",
    "yis2 = [5, 726, 73031, 7341744]\n",
    "\n",
    "xrss = [1, 2, 3, 4, 5, 6, 7]\n",
    "yrss = [20, 30, 160, 780, 3500, 15740, 74480]\n",
    "\n",
    "xaisrss = [1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "yaisrss = [20, 20, 40, 100, 250, 620, 1580, 4050, 9800]\n",
    "\n",
    "xtrsr = [3, 4, 5, 6, 7, 8, 9]\n",
    "ytr = [17, 33, 129, 513, 1025, 4097, 16385]  # Trapezium Rule\n",
    "ysr = [9, 17, 33, 65, 65, 129, 257]  # Simpson's Rule\n",
    "\n",
    "plt.semilogy(xis, yis1, marker=\"x\", label=\"MC Uniform\", c=\"black\")\n",
    "plt.semilogy(xis, yis2, marker=\"x\", label=\"MC IS\", c=\"red\")\n",
    "plt.semilogy(xrss, yrss, marker=\"x\", label=\"MC RSS\", c=\"orange\")\n",
    "plt.semilogy(xaisrss, yaisrss, marker=\"x\", label=\"MC AIS+RSS\", c=\"green\")\n",
    "plt.semilogy(xtrsr, ytr, marker=\"x\", label=\"Trapezium\", c=\"blue\")\n",
    "plt.semilogy(xtrsr, ysr, marker=\"x\", label=\"Simpson's\", c=\"purple\")\n",
    "plt.xlabel(\"Accuracy, $-\\log_{10}(\\epsilon)$\")\n",
    "plt.ylabel(\"Evaluations, $K$\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "CP-Project.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
